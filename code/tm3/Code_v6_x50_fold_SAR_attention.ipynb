{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkerynh\u001b[0m (\u001b[33mkerynhan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/wandb/run-20240811_074458-ek34ttdj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kerynhan/v6_x50_fold/runs/ek34ttdj' target=\"_blank\">fold-voting_SAR_attention</a></strong> to <a href='https://wandb.ai/kerynhan/v6_x50_fold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kerynhan/v6_x50_fold' target=\"_blank\">https://wandb.ai/kerynhan/v6_x50_fold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kerynhan/v6_x50_fold/runs/ek34ttdj' target=\"_blank\">https://wandb.ai/kerynhan/v6_x50_fold/runs/ek34ttdj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4782: 100%|██████████| 3925/3925 [02:03<00:00, 31.73it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:12<00:00, 76.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.8379, Train Acc: 0.7167, Train F1: 0.6974\n",
      "Epoch 1/30, Val Loss: 0.2719, Val Acc: 0.8915, Val F1: 0.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3339: 100%|██████████| 3925/3925 [02:03<00:00, 31.90it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:12<00:00, 78.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.3248, Train Acc: 0.8960, Train F1: 0.8879\n",
      "Epoch 2/30, Val Loss: 0.1510, Val Acc: 0.9487, Val F1: 0.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3796: 100%|██████████| 3925/3925 [02:03<00:00, 31.79it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:12<00:00, 78.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.2295, Train Acc: 0.9366, Train F1: 0.9330\n",
      "Epoch 3/30, Val Loss: 0.1631, Val Acc: 0.9627, Val F1: 0.9613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3204: 100%|██████████| 3925/3925 [02:03<00:00, 31.87it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:12<00:00, 78.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.1885, Train Acc: 0.9565, Train F1: 0.9541\n",
      "Epoch 4/30, Val Loss: 0.0770, Val Acc: 0.9813, Val F1: 0.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [02:03<00:00, 31.79it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:12<00:00, 79.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.1583, Train Acc: 0.9663, Train F1: 0.9642\n",
      "Epoch 5/30, Val Loss: 0.0738, Val Acc: 0.9850, Val F1: 0.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0011: 100%|██████████| 3925/3925 [02:03<00:00, 31.80it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:12<00:00, 78.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.1413, Train Acc: 0.9722, Train F1: 0.9705\n",
      "Epoch 6/30, Val Loss: 0.0500, Val Acc: 0.9891, Val F1: 0.9889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0389: 100%|██████████| 3925/3925 [02:03<00:00, 31.80it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:12<00:00, 78.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.1338, Train Acc: 0.9757, Train F1: 0.9744\n",
      "Epoch 7/30, Val Loss: 0.0407, Val Acc: 0.9905, Val F1: 0.9897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [02:03<00:00, 31.84it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:12<00:00, 78.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.1234, Train Acc: 0.9782, Train F1: 0.9769\n",
      "Epoch 8/30, Val Loss: 0.0437, Val Acc: 0.9915, Val F1: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0007: 100%|██████████| 3925/3925 [02:49<00:00, 23.11it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:27<00:00, 36.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.1179, Train Acc: 0.9801, Train F1: 0.9787\n",
      "Epoch 9/30, Val Loss: 0.0312, Val Acc: 0.9936, Val F1: 0.9934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2092: 100%|██████████| 3925/3925 [03:39<00:00, 17.87it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:27<00:00, 36.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.1049, Train Acc: 0.9809, Train F1: 0.9799\n",
      "Epoch 10/30, Val Loss: 0.0321, Val Acc: 0.9948, Val F1: 0.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0138: 100%|██████████| 3925/3925 [03:39<00:00, 17.91it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:27<00:00, 36.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.1011, Train Acc: 0.9827, Train F1: 0.9815\n",
      "Epoch 11/30, Val Loss: 0.0313, Val Acc: 0.9940, Val F1: 0.9938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [03:40<00:00, 17.78it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:27<00:00, 36.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.0912, Train Acc: 0.9847, Train F1: 0.9836\n",
      "Epoch 12/30, Val Loss: 0.0321, Val Acc: 0.9946, Val F1: 0.9943\n",
      "Epoch 00012: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Early stopping triggered at epoch 12\n",
      "Fold 1 Macro F1 Score: 0.9943\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7931: 100%|██████████| 3925/3925 [03:40<00:00, 17.83it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:27<00:00, 36.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.8263, Train Acc: 0.7212, Train F1: 0.7039\n",
      "Epoch 1/30, Val Loss: 0.2675, Val Acc: 0.8992, Val F1: 0.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6704: 100%|██████████| 3925/3925 [03:40<00:00, 17.82it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:27<00:00, 36.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.3117, Train Acc: 0.9009, Train F1: 0.8940\n",
      "Epoch 2/30, Val Loss: 0.1562, Val Acc: 0.9479, Val F1: 0.9455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3413: 100%|██████████| 3925/3925 [03:42<00:00, 17.66it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:27<00:00, 36.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.2214, Train Acc: 0.9386, Train F1: 0.9352\n",
      "Epoch 3/30, Val Loss: 0.1040, Val Acc: 0.9714, Val F1: 0.9699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0666: 100%|██████████| 3925/3925 [03:40<00:00, 17.82it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:27<00:00, 36.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.1810, Train Acc: 0.9574, Train F1: 0.9550\n",
      "Epoch 4/30, Val Loss: 0.0916, Val Acc: 0.9806, Val F1: 0.9794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0033: 100%|██████████| 3925/3925 [03:40<00:00, 17.83it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:27<00:00, 36.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.1532, Train Acc: 0.9665, Train F1: 0.9649\n",
      "Epoch 5/30, Val Loss: 0.0737, Val Acc: 0.9861, Val F1: 0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 3925/3925 [03:42<00:00, 17.67it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:27<00:00, 36.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.1470, Train Acc: 0.9709, Train F1: 0.9694\n",
      "Epoch 6/30, Val Loss: 0.3888, Val Acc: 0.9834, Val F1: 0.9835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1313: 100%|██████████| 3925/3925 [03:39<00:00, 17.85it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:27<00:00, 36.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.1298, Train Acc: 0.9763, Train F1: 0.9750\n",
      "Epoch 7/30, Val Loss: 0.0366, Val Acc: 0.9925, Val F1: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [03:39<00:00, 17.84it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:33<00:00, 29.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.1162, Train Acc: 0.9783, Train F1: 0.9772\n",
      "Epoch 8/30, Val Loss: 0.0872, Val Acc: 0.9911, Val F1: 0.9909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0823: 100%|██████████| 3925/3925 [05:24<00:00, 12.09it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.1126, Train Acc: 0.9800, Train F1: 0.9789\n",
      "Epoch 9/30, Val Loss: 0.0602, Val Acc: 0.9903, Val F1: 0.9899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0429: 100%|██████████| 3925/3925 [06:17<00:00, 10.41it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:56<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.1040, Train Acc: 0.9818, Train F1: 0.9806\n",
      "Epoch 10/30, Val Loss: 0.0664, Val Acc: 0.9927, Val F1: 0.9925\n",
      "Epoch 00010: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Early stopping triggered at epoch 10\n",
      "Fold 2 Macro F1 Score: 0.9925\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3163: 100%|██████████| 3925/3925 [07:27<00:00,  8.78it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:57<00:00, 17.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.8563, Train Acc: 0.7087, Train F1: 0.6891\n",
      "Epoch 1/30, Val Loss: 0.2677, Val Acc: 0.8980, Val F1: 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2618: 100%|██████████| 3925/3925 [07:26<00:00,  8.79it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:56<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.3293, Train Acc: 0.8935, Train F1: 0.8855\n",
      "Epoch 2/30, Val Loss: 0.1307, Val Acc: 0.9543, Val F1: 0.9528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3013: 100%|██████████| 3925/3925 [07:23<00:00,  8.86it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:56<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.2300, Train Acc: 0.9371, Train F1: 0.9336\n",
      "Epoch 3/30, Val Loss: 0.0774, Val Acc: 0.9763, Val F1: 0.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2534: 100%|██████████| 3925/3925 [07:26<00:00,  8.79it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:56<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.1806, Train Acc: 0.9574, Train F1: 0.9551\n",
      "Epoch 4/30, Val Loss: 0.0806, Val Acc: 0.9816, Val F1: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0006: 100%|██████████| 3925/3925 [07:26<00:00,  8.79it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:56<00:00, 17.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.1632, Train Acc: 0.9665, Train F1: 0.9644\n",
      "Epoch 5/30, Val Loss: 0.0501, Val Acc: 0.9883, Val F1: 0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [07:26<00:00,  8.79it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:55<00:00, 17.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.1411, Train Acc: 0.9721, Train F1: 0.9705\n",
      "Epoch 6/30, Val Loss: 0.0530, Val Acc: 0.9892, Val F1: 0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0404: 100%|██████████| 3925/3925 [07:26<00:00,  8.80it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:56<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.1266, Train Acc: 0.9778, Train F1: 0.9765\n",
      "Epoch 7/30, Val Loss: 0.0352, Val Acc: 0.9914, Val F1: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 3925/3925 [07:26<00:00,  8.79it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:56<00:00, 17.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.1225, Train Acc: 0.9777, Train F1: 0.9766\n",
      "Epoch 8/30, Val Loss: 0.0411, Val Acc: 0.9913, Val F1: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0030: 100%|██████████| 3925/3925 [07:26<00:00,  8.78it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:56<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.1099, Train Acc: 0.9815, Train F1: 0.9802\n",
      "Epoch 9/30, Val Loss: 0.0271, Val Acc: 0.9950, Val F1: 0.9948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [07:26<00:00,  8.80it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:56<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.1026, Train Acc: 0.9827, Train F1: 0.9817\n",
      "Epoch 10/30, Val Loss: 0.0392, Val Acc: 0.9927, Val F1: 0.9924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [07:25<00:00,  8.80it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:56<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.1017, Train Acc: 0.9835, Train F1: 0.9826\n",
      "Epoch 11/30, Val Loss: 0.0461, Val Acc: 0.9938, Val F1: 0.9933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2392: 100%|██████████| 3925/3925 [07:25<00:00,  8.81it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:56<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.0907, Train Acc: 0.9848, Train F1: 0.9840\n",
      "Epoch 12/30, Val Loss: 0.0320, Val Acc: 0.9953, Val F1: 0.9949\n",
      "Epoch 00012: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Early stopping triggered at epoch 12\n",
      "Fold 3 Macro F1 Score: 0.9949\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2036: 100%|██████████| 3925/3925 [07:25<00:00,  8.81it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:50<00:00, 19.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.8317, Train Acc: 0.7182, Train F1: 0.6995\n",
      "Epoch 1/30, Val Loss: 0.2633, Val Acc: 0.8966, Val F1: 0.8871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2148: 100%|██████████| 3925/3925 [05:24<00:00, 12.09it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:40<00:00, 24.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.3197, Train Acc: 0.8980, Train F1: 0.8906\n",
      "Epoch 2/30, Val Loss: 0.1571, Val Acc: 0.9513, Val F1: 0.9468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0718: 100%|██████████| 3925/3925 [05:24<00:00, 12.10it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.2254, Train Acc: 0.9370, Train F1: 0.9330\n",
      "Epoch 3/30, Val Loss: 0.0963, Val Acc: 0.9728, Val F1: 0.9708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4923: 100%|██████████| 3925/3925 [05:24<00:00, 12.10it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:40<00:00, 24.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.1797, Train Acc: 0.9568, Train F1: 0.9544\n",
      "Epoch 4/30, Val Loss: 0.0826, Val Acc: 0.9813, Val F1: 0.9801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002: 100%|██████████| 3925/3925 [05:24<00:00, 12.08it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:40<00:00, 24.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.1601, Train Acc: 0.9668, Train F1: 0.9649\n",
      "Epoch 5/30, Val Loss: 0.0823, Val Acc: 0.9834, Val F1: 0.9823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 3925/3925 [05:23<00:00, 12.12it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:40<00:00, 24.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.1446, Train Acc: 0.9711, Train F1: 0.9695\n",
      "Epoch 6/30, Val Loss: 0.0388, Val Acc: 0.9910, Val F1: 0.9908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2241: 100%|██████████| 3925/3925 [05:23<00:00, 12.12it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.1318, Train Acc: 0.9757, Train F1: 0.9742\n",
      "Epoch 7/30, Val Loss: 0.0589, Val Acc: 0.9882, Val F1: 0.9877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [05:25<00:00, 12.08it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:46<00:00, 21.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.1166, Train Acc: 0.9783, Train F1: 0.9770\n",
      "Epoch 8/30, Val Loss: 0.0371, Val Acc: 0.9914, Val F1: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2407: 100%|██████████| 3925/3925 [07:17<00:00,  8.97it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:56<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.1110, Train Acc: 0.9810, Train F1: 0.9800\n",
      "Epoch 9/30, Val Loss: 0.0279, Val Acc: 0.9949, Val F1: 0.9947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [07:17<00:00,  8.96it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:44<00:00, 22.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.1061, Train Acc: 0.9814, Train F1: 0.9805\n",
      "Epoch 10/30, Val Loss: 0.0428, Val Acc: 0.9929, Val F1: 0.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0014: 100%|██████████| 3925/3925 [05:25<00:00, 12.08it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:40<00:00, 24.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.1005, Train Acc: 0.9836, Train F1: 0.9824\n",
      "Epoch 11/30, Val Loss: 0.0504, Val Acc: 0.9925, Val F1: 0.9921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [05:24<00:00, 12.11it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:40<00:00, 24.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.0943, Train Acc: 0.9843, Train F1: 0.9832\n",
      "Epoch 12/30, Val Loss: 0.0248, Val Acc: 0.9948, Val F1: 0.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [05:23<00:00, 12.12it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Loss: 0.0925, Train Acc: 0.9849, Train F1: 0.9839\n",
      "Epoch 13/30, Val Loss: 0.0266, Val Acc: 0.9956, Val F1: 0.9951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 3925/3925 [05:26<00:00, 12.04it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Loss: 0.0902, Train Acc: 0.9855, Train F1: 0.9843\n",
      "Epoch 14/30, Val Loss: 0.0291, Val Acc: 0.9952, Val F1: 0.9949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [05:24<00:00, 12.09it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Loss: 0.0785, Train Acc: 0.9867, Train F1: 0.9859\n",
      "Epoch 15/30, Val Loss: 0.0264, Val Acc: 0.9953, Val F1: 0.9948\n",
      "Epoch 00015: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Early stopping triggered at epoch 15\n",
      "Fold 4 Macro F1 Score: 0.9948\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5559: 100%|██████████| 3925/3925 [05:24<00:00, 12.09it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.8474, Train Acc: 0.7103, Train F1: 0.6934\n",
      "Epoch 1/30, Val Loss: 0.2503, Val Acc: 0.9008, Val F1: 0.8918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8021: 100%|██████████| 3925/3925 [05:24<00:00, 12.11it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:40<00:00, 24.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.3284, Train Acc: 0.8940, Train F1: 0.8861\n",
      "Epoch 2/30, Val Loss: 0.1516, Val Acc: 0.9474, Val F1: 0.9437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0671: 100%|██████████| 3925/3925 [05:24<00:00, 12.08it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.2311, Train Acc: 0.9365, Train F1: 0.9328\n",
      "Epoch 3/30, Val Loss: 0.0857, Val Acc: 0.9725, Val F1: 0.9710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1384: 100%|██████████| 3925/3925 [05:24<00:00, 12.08it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.1892, Train Acc: 0.9559, Train F1: 0.9532\n",
      "Epoch 4/30, Val Loss: 0.1233, Val Acc: 0.9759, Val F1: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [05:25<00:00, 12.05it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:40<00:00, 24.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.1637, Train Acc: 0.9651, Train F1: 0.9632\n",
      "Epoch 5/30, Val Loss: 0.0490, Val Acc: 0.9876, Val F1: 0.9872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0037: 100%|██████████| 3925/3925 [05:24<00:00, 12.09it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.1397, Train Acc: 0.9723, Train F1: 0.9706\n",
      "Epoch 6/30, Val Loss: 0.0652, Val Acc: 0.9875, Val F1: 0.9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0135: 100%|██████████| 3925/3925 [05:23<00:00, 12.12it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.1263, Train Acc: 0.9764, Train F1: 0.9749\n",
      "Epoch 7/30, Val Loss: 0.0577, Val Acc: 0.9899, Val F1: 0.9896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002: 100%|██████████| 3925/3925 [05:25<00:00, 12.06it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.1282, Train Acc: 0.9773, Train F1: 0.9761\n",
      "Epoch 8/30, Val Loss: 0.0305, Val Acc: 0.9932, Val F1: 0.9928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [05:24<00:00, 12.10it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.1124, Train Acc: 0.9812, Train F1: 0.9800\n",
      "Epoch 9/30, Val Loss: 0.0539, Val Acc: 0.9909, Val F1: 0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [05:24<00:00, 12.11it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:39<00:00, 24.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.1005, Train Acc: 0.9816, Train F1: 0.9807\n",
      "Epoch 10/30, Val Loss: 0.0278, Val Acc: 0.9955, Val F1: 0.9953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [05:25<00:00, 12.07it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:40<00:00, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.1013, Train Acc: 0.9831, Train F1: 0.9821\n",
      "Epoch 11/30, Val Loss: 0.0572, Val Acc: 0.9933, Val F1: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 3925/3925 [05:23<00:00, 12.12it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:40<00:00, 24.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.0933, Train Acc: 0.9848, Train F1: 0.9840\n",
      "Epoch 12/30, Val Loss: 0.0666, Val Acc: 0.9924, Val F1: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 3925/3925 [05:24<00:00, 12.11it/s]\n",
      "Validating: 100%|██████████| 982/982 [00:40<00:00, 24.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Loss: 0.0948, Train Acc: 0.9855, Train F1: 0.9845\n",
      "Epoch 13/30, Val Loss: 0.0413, Val Acc: 0.9959, Val F1: 0.9958\n",
      "Epoch 00013: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Early stopping triggered at epoch 13\n",
      "Fold 5 Macro F1 Score: 0.9958\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efec4eed136b4bb3940ea66931334a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▃▃▄▅▅▆▁▂▃▃▄▅▅▁▃▃▄▅▅▆▁▁▃▃▄▅▅▇▇█▁▂▃▃▅▅▆▇</td></tr><tr><td>train_acc</td><td>▁▆▇▇████▁▇▇████▆▇▇████▁▆▇███████▆▇▇█████</td></tr><tr><td>train_f1</td><td>▁▆▇▇████▁▇▇████▆▇▇████▁▆▇███████▆▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁█▂▂▂▁▁▁▃▂▂▁▁▁▁█▃▂▂▁▁▁▁▁▁▃▂▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▇▇████▂▆▇▇███▅▇▇████▁▅▇█▇█████▅▆▇▇████</td></tr><tr><td>val_f1</td><td>▁▅▇▇████▂▇▇▇███▆▇█████▂▅▇███████▅▇██████</td></tr><tr><td>val_loss</td><td>▆▃▂▂▁▁▁▁▆▃▂█▁▂▂▃▂▁▁▁▁▁▆▄▂▁▂▁▁▁▁▁▃▂▁▂▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>13</td></tr><tr><td>train_acc</td><td>0.98546</td></tr><tr><td>train_f1</td><td>0.98447</td></tr><tr><td>train_loss</td><td>0.09484</td></tr><tr><td>val_acc</td><td>0.99592</td></tr><tr><td>val_f1</td><td>0.99582</td></tr><tr><td>val_loss</td><td>0.04128</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-voting_SAR_attention</strong> at: <a href='https://wandb.ai/kerynhan/v6_x50_fold/runs/ek34ttdj' target=\"_blank\">https://wandb.ai/kerynhan/v6_x50_fold/runs/ek34ttdj</a><br/> View project at: <a href='https://wandb.ai/kerynhan/v6_x50_fold' target=\"_blank\">https://wandb.ai/kerynhan/v6_x50_fold</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240811_074458-ek34ttdj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from PIL import Image\n",
    "import wandb\n",
    "\n",
    "# 시드 고정\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# WANDB 초기화\n",
    "wandb.login()\n",
    "wandb.init(project='v6_x50_fold', name='fold-voting_SAR_attention')\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 데이터 경로 및 설정\n",
    "data_path_train = 'data/augmented_v3_x50/'\n",
    "data_path_test = 'data/test/'\n",
    "img_size = 224\n",
    "LR = 1e-4\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "num_workers = 8\n",
    "patience = 3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "DROPOUT_PROB = 0.4\n",
    "\n",
    "# torchvision.transforms를 사용하여 추가적인 변형 정의\n",
    "additional_transforms = T.Compose([\n",
    "    T.RandomErasing(p=0.3, scale=(0.02, 0.33), ratio=(0.3, 3.3), value='random'),\n",
    "])\n",
    "\n",
    "# 데이터셋 클래스에서 추가적인 변형을 적용할 수 있도록 수정\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, path, transform=None, additional_transforms=None):\n",
    "        self.df = df.values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.additional_transforms = additional_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = Image.open(os.path.join(self.path, name)).convert(\"RGB\")\n",
    "        \n",
    "        # 기본 transform 적용\n",
    "        if self.transform:\n",
    "            img = self.transform(image=np.array(img))['image']  # numpy 배열로 변환 후 transform 적용\n",
    "        \n",
    "        # 추가 변형 적용\n",
    "        if self.additional_transforms:\n",
    "            img = self.additional_transforms(img)\n",
    "        \n",
    "        return img, target\n",
    "\n",
    "# SAR 모델 정의\n",
    "class CustomSAR(nn.Module):\n",
    "    def __init__(self, num_classes=17, dropout_prob=0.5, embed_dim=1024):\n",
    "        super(CustomSAR, self).__init__()\n",
    "        self.model = timm.create_model('resnet50', pretrained=True)\n",
    "        num_features = self.model.fc.in_features\n",
    "        \n",
    "        # Attention 레이어를 위한 FC 레이어\n",
    "        self.fc1 = nn.Linear(num_features, embed_dim)\n",
    "        \n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=8, dropout=dropout_prob)\n",
    "        \n",
    "        # Attention 후 최종 분류를 위한 FC 레이어\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.model.forward_features(x)  # ResNet의 특징 추출\n",
    "\n",
    "        # Global Average Pooling 적용 (feature map을 평탄화하여 벡터로 변환)\n",
    "        features = torch.mean(features, dim=[2, 3])  # [Batch Size, Channels]\n",
    "\n",
    "        features = self.fc1(features)  # 임베딩 차원으로 변환\n",
    "\n",
    "        # features의 차원을 [Seq Length, Batch Size, Embedding Dim]으로 맞춤\n",
    "        features = features.unsqueeze(0)  # [1, Batch Size, Embedding Dim] 형태로 변경\n",
    "\n",
    "        attn_output, _ = self.attention(features, features, features)\n",
    "        attn_output = attn_output.squeeze(0)  # [Batch Size, Embedding Dim] 형태로 변환\n",
    "\n",
    "        return self.fc2(attn_output)  # 최종 분류 레이어로 전달\n",
    "\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, scaler, clip_value=0.5):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret\n",
    "\n",
    "# 검증 함수 정의\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets in tqdm(loader, desc=\"Validating\"):\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "\n",
    "    return ret\n",
    "\n",
    "# augmentation을 위한 transform 정의\n",
    "trn_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    A.CoarseDropout(p=0.5),\n",
    "    A.GaussianBlur(p=0.3),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# 데이터 로드\n",
    "train_df_test = pd.read_csv('data/augment_v3_x50.csv')\n",
    "test_df_test = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "# 클래스별 가중치 계산\n",
    "class_counts = train_df_test['target'].value_counts().sort_index()\n",
    "total_samples = len(train_df_test)\n",
    "class_weights = [total_samples / class_counts[i] for i in range(len(class_counts))]\n",
    "class_weights = np.array(class_weights)\n",
    "class_weights = class_weights / class_weights.sum() * len(class_counts)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Stratified K-Fold 설정\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "folds = list(skf.split(train_df_test['ID'], train_df_test['target']))\n",
    "\n",
    "# 학습 및 검증 루프\n",
    "best_val_loss = float('inf')\n",
    "fold_val_metrics = []\n",
    "best_model_paths = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_df_test.iloc[train_idx],\n",
    "        data_path_train,\n",
    "        transform=trn_transform,\n",
    "        additional_transforms=additional_transforms  # 추가 변형 적용\n",
    "    )\n",
    "\n",
    "    val_dataset = ImageDataset(\n",
    "        train_df_test.iloc[val_idx],\n",
    "        data_path_train,\n",
    "        transform=trn_transform  # 수정된 부분\n",
    "    )\n",
    "\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # 모델 정의 (SAR로 변경)\n",
    "    model = CustomSAR(num_classes=17, dropout_prob=DROPOUT_PROB).to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=2, verbose=True)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    fold_best_val_loss = float('inf')\n",
    "    fold_best_model_path = f'best_model_fold_{fold + 1}_fold_x50_SAR_attention.pth'\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_metrics = train_one_epoch(trn_loader, model, optimizer, loss_fn, device, scaler)\n",
    "        val_metrics = validate(val_loader, model, loss_fn, device)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {train_metrics['train_loss']:.4f}, Train Acc: {train_metrics['train_acc']:.4f}, Train F1: {train_metrics['train_f1']:.4f}\")\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}, Val Loss: {val_metrics['val_loss']:.4f}, Val Acc: {val_metrics['val_acc']:.4f}, Val F1: {val_metrics['val_f1']:.4f}\")\n",
    "\n",
    "        # WANDB 로그 기록\n",
    "        wandb.log({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_metrics['train_loss'],\n",
    "            'train_acc': train_metrics['train_acc'],\n",
    "            'train_f1': train_metrics['train_f1'],\n",
    "            'val_loss': val_metrics['val_loss'],\n",
    "            'val_acc': val_metrics['val_acc'],\n",
    "            'val_f1': val_metrics['val_f1']\n",
    "        })\n",
    "\n",
    "        scheduler.step(val_metrics['val_loss'])  # 수정된 부분\n",
    "\n",
    "        if val_metrics['val_loss'] < fold_best_val_loss:\n",
    "            fold_best_val_loss = val_metrics['val_loss']\n",
    "            torch.save(model.state_dict(), fold_best_model_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    best_model_paths.append(fold_best_model_path)\n",
    "    fold_val_metrics.append((fold_best_val_loss, val_metrics['val_f1']))\n",
    "    print(f\"Fold {fold + 1} Macro F1 Score: {val_metrics['val_f1']:.4f}\")\n",
    "\n",
    "wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Validation Loss: 0.0098, Validation Accuracy: 0.9980, Validation F1 Score: 0.9980\n",
      "Fold 2 Validation Loss: 0.0135, Validation Accuracy: 0.9973, Validation F1 Score: 0.9973\n",
      "Fold 3 Validation Loss: 0.0046, Validation Accuracy: 0.9989, Validation F1 Score: 0.9987\n",
      "Fold 4 Validation Loss: 0.0058, Validation Accuracy: 0.9987, Validation F1 Score: 0.9986\n",
      "Fold 5 Validation Loss: 0.0040, Validation Accuracy: 0.9991, Validation F1 Score: 0.9991\n",
      "Mean Validation Loss: 0.0075, Mean Validation Accuracy: 0.9984, Mean Validation F1 Score: 0.9983\n",
      "최종 제출 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# Test 데이터셋에 대한 변환 정의\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# 테스트 데이터 예측 및 결과 저장\n",
    "test_dataset = ImageDataset(test_df_test, data_path_test, transform=tst_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "# Validation 결과 저장을 위한 리스트\n",
    "val_f1_scores = []\n",
    "val_acc_scores = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "# model_paths = [\n",
    "#     'best_model_fold_1_fold_x50_SAR_attention.pth',\n",
    "#     'best_model_fold_2_fold_x50_SAR_attention.pth',\n",
    "#     'best_model_fold_3_fold_x50_SAR_attention.pth',\n",
    "#     'best_model_fold_4_fold_x50_SAR_attention.pth',\n",
    "#     'best_model_fold_5_fold_x50_SAR_attention.pth'\n",
    "# ]\n",
    "\n",
    "# 폴드별 예측 결과 저장\n",
    "fold_preds = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "    model = CustomSAR(num_classes=17, dropout_prob=DROPOUT_PROB).to(device)\n",
    "    model.load_state_dict(torch.load(best_model_paths[fold]))\n",
    "    model.eval()\n",
    "\n",
    "    val_dataset = ImageDataset(train_df_test.iloc[val_idx], data_path_train, transform=tst_transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    val_preds = []\n",
    "    val_targets = []\n",
    "    val_loss = 0.0\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            output = model(images)\n",
    "            loss = loss_fn(output, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_preds.extend(output.argmax(dim=1).cpu().numpy())\n",
    "            val_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_f1 = f1_score(val_targets, val_preds, average='macro')\n",
    "    val_acc = accuracy_score(val_targets, val_preds)\n",
    "\n",
    "    val_f1_scores.append(val_f1)\n",
    "    val_acc_scores.append(val_acc)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Fold {fold + 1} Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "    # 테스트 데이터에 대한 예측\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            output = model(images)\n",
    "            preds.append(output.softmax(dim=1).cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    fold_preds.append(preds)\n",
    "\n",
    "# 폴드별 예측을 평균하여 최종 예측 생성\n",
    "final_preds = np.mean(fold_preds, axis=0)\n",
    "final_class_preds = np.argmax(final_preds, axis=1)\n",
    "\n",
    "# 결과 저장\n",
    "submission = pd.DataFrame({'ID': test_df_test['ID'], 'target': final_class_preds})\n",
    "submission.to_csv('submit_v6_x50_SAR_attention.csv', index=False)\n",
    "\n",
    "# 최종 검증 성능 출력\n",
    "print(f\"Mean Validation Loss: {np.mean(val_losses):.4f}, Mean Validation Accuracy: {np.mean(val_acc_scores):.4f}, Mean Validation F1 Score: {np.mean(val_f1_scores):.4f}\")\n",
    "print(\"최종 제출 파일이 저장되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
