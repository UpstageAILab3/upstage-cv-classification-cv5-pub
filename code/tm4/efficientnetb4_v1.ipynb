{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"OliaDaX_lwou"},"source":["# **📄 Document type classification **\n","\n","## Contents\n","- Prepare Environments\n","- Import Library & Define Functions\n","- Hyper-parameters\n","- Load Data\n","- Train Model\n","- Inference & Save File\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zkH9T_86lDSS"},"source":["## 1. Prepare Environments\n","\n","* 필요한 라이브러리를 설치합니다."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8489,"status":"ok","timestamp":1700314558888,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"NC8V-D393wY4","outputId":"e9927325-26c4-4b89-9c51-c1d6541388d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.12)\n","Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.0)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.0)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.24.5)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.9.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (4.12.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (1.11.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.0.3)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (2023.9.2)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (23.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (4.65.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm) (2.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.6)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\n","Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (4.1.0)\n","Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.27.3)\n","Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.0)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.12.0)\n","Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.0.0)\n","Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.9.1.post1)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.0)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (23.1)\n","Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.9.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.5)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.0)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2021.11.10)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.9.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# 필요한 라이브러리 설치\n","!pip install timm\n","!pip install wandb\n","!pip install matplotlib\n","!pip install transformers"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PXa_FPM73R9f"},"source":["## 2. Import Library & Define Functions\n","* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n","* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9396,"status":"ok","timestamp":1700314592802,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"3BaoIkv5Xwa0"},"outputs":[],"source":["import os\n","import time\n","import random\n","import copy\n","\n","import timm\n","import torch\n","import pandas as pd\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from albumentations.pytorch import ToTensorV2\n","import albumentations as A\n","from albumentations import ImageOnlyTransform\n","from augraphy import *\n","from torch.optim import Adam\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset\n","\n","from PIL import Image\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","import wandb\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# 잘못된label 수정\n","train_df = pd.read_csv(\"../data/train.csv\")\n","train_df.loc[428, 'target'] = 7\n","train_df.loc[1095, 'target'] = 14\n","train_df.loc[862, 'target'] = 3\n","train_df.loc[192, 'target'] = 7\n","train_df.loc[1237, 'target'] = 14\n","train_df.loc[38, 'target'] = 10\n","train_df.loc[340, 'target'] = 10\n","\n","train_df.to_csv(\"../data/train.csv\", index=False)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# 시드를 고정합니다.\n","SEED = 42\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":241,"status":"ok","timestamp":1700314772722,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"Hyl8oAy6TZAu"},"outputs":[],"source":["##중지1\n","\n","# 데이터셋 클래스를 정의합니다.\n","class ImageDataset(Dataset):\n","    def __init__(self, csv, path, transform=None, oversample=False):\n","        self.df = pd.read_csv(csv)\n","        self.path = path\n","        self.transform = transform\n","        self.oversample = oversample\n","\n","        if self.oversample:\n","            class_counts = np.bincount(self.df.values[:, 1].astype(int))\n","\n","            max_class_count = max(class_counts)\n","            oversample_factors = [max_class_count // count for count in class_counts]\n","            oversample_factors[3] = 2\n","            oversample_factors[7] = 2 \n","\n","            oversampled_data = [self.df.values[self.df.values[:, 1] == cls].repeat(factor, axis=0) for cls, factor in enumerate(oversample_factors)]\n","            oversampled_data = np.vstack(oversampled_data)\n","\n","            self.df = pd.DataFrame(oversampled_data, columns=self.df.columns)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        name, target = self.df.iloc[idx]\n","        img = np.array(Image.open(os.path.join(self.path, name)).convert(\"RGB\"))\n","        \n","        if self.transform:\n","            img = self.transform(image=img)['image']\n","        return img, target\n","    \n","meta_data = pd.read_csv('/data/ephemeral/home/data/meta.csv')\n","label_to_class_name = dict(zip(meta_data['target'], meta_data['class_name']))"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["class ImageDataset(Dataset):\n","    def __init__(self, csv_files, img_paths, transform=None):\n","\n","        if isinstance(csv_files, str):\n","            csv_files = [csv_files]\n","        if isinstance(img_paths, str):\n","            img_paths = [img_paths]\n","\n","        self.df = pd.concat([pd.read_csv(csv) for csv in csv_files], ignore_index=True)\n","        self.img_paths = img_paths\n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        # 데이터프레임에서 이미지 이름(ID)과 타겟 값을 가져오기\n","        img_name, target = self.df.iloc[idx]['ID'], self.df.iloc[idx]['target']\n","        img = None\n","        # target 값을 정수형으로 변환\n","        target = int(target)  # target 값을 정수형으로 변환합니다.\n","\n","        # 이미지 경로 리스트를 순회하며 이미지 파일을 찾기\n","        for path in self.img_paths:\n","            img_path = os.path.join(path, img_name)\n","            if os.path.exists(img_path):\n","                img = Image.open(img_path).convert('RGB')\n","                # Move transform usage here\n","                inputs = self.transform(images=img, return_tensors=\"pt\")\n","                input_pixels = inputs['pixel_values'].squeeze()  # Remove batch dimension\n","                break\n","\n","\n","        return input_pixels, torch.tensor(target, dtype=torch.long)\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1700315066028,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"kTECBJfVTbdl"},"outputs":[],"source":["# one epoch 학습을 위한 함수\n","def training(model, dataloader, criterion, optimizer, device, epoch, num_epochs):\n","    model.train()\n","    train_loss = 0\n","    preds_list = []\n","    targets_list = []\n","\n","    pbar = tqdm(dataloader)\n","    for images, labels in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        model.zero_grad(set_to_none=True)\n","\n","        preds = model(images)\n","        loss = criterion(preds, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n","        targets_list.extend(labels.detach().cpu().numpy())\n","\n","        pbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {loss.item()}\")\n","        \n","    train_loss /= len(dataloader)\n","    train_acc = accuracy_score(targets_list, preds_list)    \n","    train_f1 = f1_score(targets_list, preds_list, average='macro')\n","\n","    return model, train_loss, train_acc, train_f1\n","\n","def evaluation(model, dataloader, criterion, device, epoch, num_epochs):\n","    model.eval()  # 모델을 평가 모드로 설정\n","    valid_loss = 0.0\n","    preds_list = []\n","    targets_list = []\n","\n","    with torch.no_grad(): # model의 업데이트 막기\n","        tbar = tqdm(dataloader)\n","        for images, labels in tbar:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            preds = model(images)\n","            loss = criterion(preds, labels)\n","\n","            valid_loss += loss.item()\n","            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n","            targets_list.extend(labels.detach().cpu().numpy())\n","\n","            tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}] - Valid Loss: {loss.item()}\")\n","\n","    valid_loss = valid_loss / len(dataloader)\n","    valid_acc = accuracy_score(targets_list, preds_list)  \n","    valid_f1 = f1_score(targets_list, preds_list, average='macro')\n","\n","    return valid_loss, valid_acc, valid_f1\n","\n","def training_loop(model, train_dataloader, valid_dataloader, criterion, optimizer, device, num_epochs, patience, model_name, run):\n","    best_valid_loss = float('inf')  \n","    early_stop_counter = 0 \n","    valid_max_accuracy = -1\n","    best_model = None\n","\n","    for epoch in range(num_epochs):\n","        model, train_loss, train_acc, train_f1 = training(model, train_dataloader, criterion, optimizer, device, epoch, num_epochs)\n","        valid_loss, valid_acc, valid_f1 = evaluation(model, valid_dataloader, criterion, device, epoch, num_epochs)\n","\n","        monitoring_value = {'train_loss': train_loss, 'train_accuracy': train_acc, 'train_f1': train_f1, \n","                            'valid_loss': valid_loss, 'valid_accuracy': valid_acc, 'valid_f1': valid_f1}\n","        \n","        run.log(monitoring_value, step=epoch)\n","        \n","        print(f'''Epoch [{epoch + 1}/{num_epochs}] Finished\n","        Train Loss: {train_loss}, Train Accuracy: {train_acc}, Train F1: {train_f1}\n","        Valid Loss: {valid_loss}, Valid Accuracy: {valid_acc}, Valid F1: {valid_f1}''')\n","\n","        if valid_acc > valid_max_accuracy:\n","          valid_max_accuracy = valid_acc\n","\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            best_model = model\n","            torch.save(model.state_dict(), f\"./model_{model_name}.pt\")\n","            early_stop_counter = 0\n","            print('Model Saved')\n","\n","        else:\n","            early_stop_counter += 1\n","\n","        if early_stop_counter >= patience:\n","            print(\"Early stopping\")\n","            break\n","\n","    return best_model, valid_max_accuracy"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Wjom43UvoXcx"},"source":["## 3. Hyper-parameters\n","* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":436,"status":"ok","timestamp":1700315112439,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"KByfAeRmXwYk"},"outputs":[{"ename":"NameError","evalue":"name 'torch' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# device\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# data config\u001b[39;00m\n\u001b[1;32m      5\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/ephemeral/home/data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}],"source":["# device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# data config\n","data_path = '/data/ephemeral/home/data/'\n","\n","# validation config\n","VALID_RATIO = 0.8\n","\n","# model config\n","model_name = 'efficientnet_b4'\n","pretrained_size = 380\n","pretrained_means = [0.485, 0.456, 0.406]\n","pretrained_stds= [0.229, 0.224, 0.225]\n","\n","# training config\n","LR = 5e-4\n","EPOCHS = 40\n","BATCH_SIZE = 32\n","dropout_ratio = 0.2\n","patience = 5\n","num_workers = 0\n","num_classes = 17\n","\n"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["66655 3140\n"]}],"source":["import os\n","\n","# 예를 들어, data_path를 절대 경로로 설정\n","data_path = \"../data/\"  # 실제 경로로 변경하세요\n","\n","csv_list = [\n","    os.path.join(data_path, \"A_train.csv\"),\n","    os.path.join(data_path, \"train.csv\"),\n","    os.path.join(data_path, \"A_13_train.csv\"),\n","    os.path.join(data_path, \"rotate_train.csv\"),\n","    os.path.join(data_path, \"rotateflip_train.csv\"),\n","    os.path.join(data_path, \"A_rotateandflip_train.csv\")\n","]\n","\n","path_list = [\n","    os.path.join(data_path, \"augmented/A\"),\n","    os.path.join(data_path, \"train\"),\n","    os.path.join(data_path, \"augmented/A_13\"),\n","    os.path.join(data_path, \"augmented/rotate\"),\n","    os.path.join(data_path, \"augmented/rotateflip\"),\n","    os.path.join(data_path, \"augmented/rotateflip\")\n","]\n","\n","def check_files(files):\n","    for file in files:\n","        if not os.path.isfile(file):\n","            print(f\"파일이 존재하지 않습니다: {file}\")\n","\n","def check_directories(directories):\n","    for directory in directories:\n","        if not os.path.isdir(directory):\n","            print(f\"디렉토리가 존재하지 않습니다: {directory}\")\n","\n","check_files(csv_list)\n","check_directories(path_list)\n","\n","import pandas as pd\n","from torch.utils.data import Dataset\n","from PIL import Image\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, csv_files, img_paths, transform=None):\n","        # CSV 파일 경로 확인\n","        for csv_file in csv_files:\n","            if not os.path.isfile(csv_file):\n","                raise FileNotFoundError(f\"CSV 파일이 존재하지 않습니다: {csv_file}\")\n","        \n","        # 모든 CSV 파일을 하나의 DataFrame으로 결합\n","        self.df = pd.concat([pd.read_csv(csv_file) for csv_file in csv_files], ignore_index=True)\n","        \n","        # 이미지 경로와 변환 함수 저장\n","        self.img_paths = img_paths\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        # 이미지 경로와 레이블 가져오기\n","        img_name = os.path.join(self.img_paths[0], self.df.iloc[idx, 0])\n","        image = Image.open(img_name)\n","        label = self.df.iloc[idx, 1]\n","\n","        # 변환 함수가 제공되면 적용\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","# 훈련 데이터셋 정의\n","trn_dataset = ImageDataset(\n","    csv_files=csv_list,\n","    img_paths=path_list,\n","    transform=train_transform\n",")\n","\n","# 테스트 데이터셋 정의\n","tst_dataset = ImageDataset(\n","    csv_files=[os.path.join(data_path, \"sample_submission.csv\")],\n","    img_paths=[os.path.join(data_path, \"test\")],  # 단일 경로도 리스트로 감싸기\n","    transform=test_transform\n",")\n","\n","print(len(trn_dataset), len(tst_dataset))\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"amum-FlIojc6"},"source":["## 4. Load Data\n","* 학습, 검증, 테스트 데이터셋과 로더를 정의합니다."]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["# train image 변환을 위한 transform 코드\n","train_transform = A.Compose([\n","    # PatternGeneratorTransform(pattern, p=0.3), # 패턴 노이즈\n","    # A.Resize(height=pretrained_size, width=pretrained_size), # 이미지 크기 조정\n","    # 이미지 긴 측면 크기 조절 후 패딩 적용\n","    A.LongestMaxSize(max_size=pretrained_size, always_apply=True), \n","    A.PadIfNeeded(min_height=pretrained_size, min_width=pretrained_size, border_mode=0, value=(255, 255, 255)),\n","    \n","    A.Normalize(mean=pretrained_means, std=pretrained_stds), # images normalization\n","    ToTensorV2() # numpy 이미지나 PIL 이미지를 PyTorch 텐서로 변환\n","])\n","\n","# test image 변환을 위한 transform 코드\n","test_transform = A.Compose([    \n","    # A.Resize(height=pretrained_size, width=pretrained_size),\n","    A.LongestMaxSize(max_size=pretrained_size, always_apply=True),\n","    A.PadIfNeeded(min_height=pretrained_size, min_width=pretrained_size, border_mode=0, value=(255, 255, 255)),\n","    \n","    A.Normalize(mean=pretrained_means, std=pretrained_stds),\n","    ToTensorV2()\n","])\n","\n","aug_test_transform = A.Compose([    \n","    A.RandomRotate90(),\n","    A.Flip(p=0.5),              \n","                        \n","    # A.Resize(height=pretrained_size, width=pretrained_size),\n","    A.LongestMaxSize(max_size=pretrained_size, always_apply=True),\n","    A.PadIfNeeded(min_height=pretrained_size, min_width=pretrained_size, border_mode=0, value=(255, 255, 255)),\n","    \n","    A.Normalize(mean=pretrained_means, std=pretrained_stds),\n","    ToTensorV2()\n","])\n","\n","# 시각화를 위한 transform 코드\n","base_transform = A.Compose([\n","    ToTensorV2()\n","])"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'img_size' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# augmentation을 위한 transform 코드\u001b[39;00m\n\u001b[1;32m      2\u001b[0m trn_transform \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 이미지 크기 조정\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     A\u001b[38;5;241m.\u001b[39mResize(height\u001b[38;5;241m=\u001b[39m\u001b[43mimg_size\u001b[49m, width\u001b[38;5;241m=\u001b[39mimg_size),\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# images normalization\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     A\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m]),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# numpy 이미지나 PIL 이미지를 PyTorch 텐서로 변환\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     ToTensorV2(),\n\u001b[1;32m      9\u001b[0m ])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# test image 변환을 위한 transform 코드\u001b[39;00m\n\u001b[1;32m     12\u001b[0m tst_transform \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     13\u001b[0m     A\u001b[38;5;241m.\u001b[39mResize(height\u001b[38;5;241m=\u001b[39mimg_size, width\u001b[38;5;241m=\u001b[39mimg_size),\n\u001b[1;32m     14\u001b[0m     A\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m]),\n\u001b[1;32m     15\u001b[0m     ToTensorV2(),\n\u001b[1;32m     16\u001b[0m ])\n","\u001b[0;31mNameError\u001b[0m: name 'img_size' is not defined"]}],"source":[]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700315112808,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"INxdmsStop2L","outputId":"49f0d412-8ce6-4d2f-ae78-d5cf3d056340"},"outputs":[{"name":"stdout","output_type":"stream","text":["14936 3140\n"]}],"source":["\n","# Training Dataset 정의\n","train_dataset = ImageDataset(\n","    data_path + '../newtest/aug_train.csv',\n","    data_path + '../newtest/train/',\n","    transform=train_transform,\n","    oversample=True\n",")\n","\n","\n","\n","# Test Dataset 정의\n","test_dataset = ImageDataset(\n","    data_path + '../newtest/sample_submission.csv',\n","    data_path + '../newtest/test/',\n","    transform=test_transform\n",")\n","\n","aug_test_dataset = ImageDataset(\n","    data_path + '../newtest/sample_submission.csv',\n","    data_path + '../newtest/test/',\n","    transform=aug_test_transform\n",")\n","\n","# 시각화용 Dataset 정의\n","train_dataset_v = ImageDataset(\n","    data_path + '../newtest/aug_train.csv',\n","    data_path + '../newtest/train/',\n","    transform=base_transform\n",")\n","\n","test_dataset_v = ImageDataset(\n","    data_path + '../newtest/sample_submission.csv',\n","    data_path + '../newtest/test/',\n","    transform=base_transform\n",")\n","\n","print(len(train_dataset), len(test_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","\n","data_path = \"../data/\"  \n","\n","csv_list = [\n","    os.path.join(data_path, \"A_train.csv\"),\n","    os.path.join(data_path, \"train.csv\"),\n","    os.path.join(data_path, \"A_13_train.csv\"),\n","    os.path.join(data_path, \"rotate_train.csv\"),\n","    os.path.join(data_path, \"rotateflip_train.csv\"),\n","    os.path.join(data_path, \"A_rotateandflip_train.csv\")\n","]\n","\n","path_list = [\n","    os.path.join(data_path, \"augmented/A\"),\n","    os.path.join(data_path, \"train\"),\n","    os.path.join(data_path, \"augmented/A_13\"),\n","    os.path.join(data_path, \"augmented/rotate\"),\n","    os.path.join(data_path, \"augmented/rotateflip\"),\n","    os.path.join(data_path, \"augmented/rotateflip\")\n","]\n","\n","def check_files(files):\n","    for file in files:\n","        if not os.path.isfile(file):\n","            print(f\"파일이 존재하지 않습니다: {file}\")\n","\n","def check_directories(directories):\n","    for directory in directories:\n","        if not os.path.isdir(directory):\n","            print(f\"디렉토리가 존재하지 않습니다: {directory}\")\n","\n","check_files(csv_list)\n","check_directories(path_list)\n","\n","import pandas as pd\n","from torch.utils.data import Dataset\n","from PIL import Image\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, csv_files, img_paths, transform=None):\n","        for csv_file in csv_files:\n","            if not os.path.isfile(csv_file):\n","                raise FileNotFoundError(f\"CSV 파일이 존재하지 않습니다: {csv_file}\")\n","        \n","        self.df = pd.concat([pd.read_csv(csv_file) for csv_file in csv_files], ignore_index=True)\n","        \n","        self.img_paths = img_paths\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.img_paths[0], self.df.iloc[idx, 0])\n","        image = Image.open(img_name)\n","        label = self.df.iloc[idx, 1]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","trn_dataset = ImageDataset(\n","    csv_files=csv_list,\n","    img_paths=path_list,\n","    transform=trn_transform\n",")\n","\n","tst_dataset = ImageDataset(\n","    csv_files=[os.path.join(data_path, \"sample_submission.csv\")],\n","    img_paths=[os.path.join(data_path, \"test\")],  \n","    transform=tst_transform\n",")\n","\n","print(len(trn_dataset), len(tst_dataset))\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train dataset 개수: 9558\n","Validation dataset 개수: 2390\n","Test dataset 개수: 3140\n"]}],"source":["total_size = len(train_dataset)\n","train_num, valid_num = int(total_size * VALID_RATIO), total_size - int(total_size * VALID_RATIO)\n","\n","generator = torch.Generator().manual_seed(SEED)\n","train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_num, valid_num], generator = generator)\n","\n","valid_data = copy.deepcopy(valid_dataset)\n","valid_data.dataset.transform = test_transform\n","\n","print(f'Train dataset 개수: {len(train_dataset)}')\n","print(f'Validation dataset 개수: {len(valid_dataset)}')\n","print(f'Test dataset 개수: {len(test_dataset)}')"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1700315112808,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"_sO03fWaQj1h"},"outputs":[],"source":["# DataLoader 정의\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=num_workers,\n","    pin_memory=True,\n","    drop_last=False\n","    )\n","\n","valid_dataloader = DataLoader(\n","    valid_dataset, \n","    batch_size = BATCH_SIZE, \n","    shuffle = False,\n","    num_workers=0,\n","    pin_memory=True\n","    )\n","\n","test_dataloader = DataLoader(\n","    test_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=0,\n","    pin_memory=True\n","    )\n","\n","aug_test_dataloader = DataLoader(\n","    aug_test_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=0,\n","    pin_memory=True\n","    )"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Nmm5h3J-pXNV"},"source":["## 5. Train Model\n","* 모델을 로드하고, 학습을 진행합니다."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["class AttentionModule(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super(AttentionModule, self).__init__()\n","        self.attention = nn.Sequential(\n","            nn.Linear(in_features, out_features),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        attention_weights = self.attention(x)\n","        return x * attention_weights\n","\n","class CustomEfficientNetB5(nn.Module):\n","    def __init__(self, num_classes, attention_size=1792):\n","        super(CustomEfficientNetB5, self).__init__()\n","        self.base_model = timm.create_model('efficientnet_b4', pretrained=True)\n","        \n","        # Remove the existing classifier\n","        self.base_model.reset_classifier(0, '')\n","\n","        # Add attention mechanism\n","        self.attention = AttentionModule(attention_size, attention_size)\n","\n","        # New classifier with attention\n","        self.classifier = nn.Linear(attention_size, num_classes)\n","        \n","    def forward(self, x):\n","        x = self.base_model(x)\n","        \n","        # Global average pooling\n","        x = x.mean([2, 3])\n","\n","        # Apply attention mechanism\n","        x = self.attention(x)\n","\n","        # Final classification\n","        x = self.classifier(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":870,"status":"ok","timestamp":1700315114067,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"FbBgFPsLT-CO"},"outputs":[],"source":["# 모델 생성\n","model = CustomEfficientNetB5(num_classes).to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = Adam(model.parameters(), lr=LR)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["CustomEfficientNetB4(\n","  (base_model): EfficientNet(\n","    (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bn1): BatchNormAct2d(\n","      48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","      (drop): Identity()\n","      (act): SiLU(inplace=True)\n","    )\n","    (blocks): Sequential(\n","      (0): Sequential(\n","        (0): DepthwiseSeparableConv(\n","          (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n","          (bn1): BatchNormAct2d(\n","            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn2): BatchNormAct2d(\n","            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (1): DepthwiseSeparableConv(\n","          (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n","          (bn1): BatchNormAct2d(\n","            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn2): BatchNormAct2d(\n","            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","      )\n","      (1): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (bn2): BatchNormAct2d(\n","            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (bn2): BatchNormAct2d(\n","            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (2): InvertedResidual(\n","          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (bn2): BatchNormAct2d(\n","            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (3): InvertedResidual(\n","          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (bn2): BatchNormAct2d(\n","            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","      )\n","      (2): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n","          (bn2): BatchNormAct2d(\n","            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n","          (bn2): BatchNormAct2d(\n","            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (2): InvertedResidual(\n","          (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n","          (bn2): BatchNormAct2d(\n","            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (3): InvertedResidual(\n","          (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n","          (bn2): BatchNormAct2d(\n","            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","      )\n","      (3): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(336, 336, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=336, bias=False)\n","          (bn2): BatchNormAct2d(\n","            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n","          (bn2): BatchNormAct2d(\n","            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (2): InvertedResidual(\n","          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n","          (bn2): BatchNormAct2d(\n","            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (3): InvertedResidual(\n","          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n","          (bn2): BatchNormAct2d(\n","            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (4): InvertedResidual(\n","          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n","          (bn2): BatchNormAct2d(\n","            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (5): InvertedResidual(\n","          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n","          (bn2): BatchNormAct2d(\n","            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","      )\n","      (4): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","          (bn2): BatchNormAct2d(\n","            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n","          (bn2): BatchNormAct2d(\n","            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (2): InvertedResidual(\n","          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n","          (bn2): BatchNormAct2d(\n","            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (3): InvertedResidual(\n","          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n","          (bn2): BatchNormAct2d(\n","            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (4): InvertedResidual(\n","          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n","          (bn2): BatchNormAct2d(\n","            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (5): InvertedResidual(\n","          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n","          (bn2): BatchNormAct2d(\n","            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","      )\n","      (5): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=960, bias=False)\n","          (bn2): BatchNormAct2d(\n","            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n","          (bn2): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (2): InvertedResidual(\n","          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n","          (bn2): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (3): InvertedResidual(\n","          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n","          (bn2): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (4): InvertedResidual(\n","          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n","          (bn2): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (5): InvertedResidual(\n","          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n","          (bn2): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (6): InvertedResidual(\n","          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n","          (bn2): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (7): InvertedResidual(\n","          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n","          (bn2): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","      )\n","      (6): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1632, bias=False)\n","          (bn2): BatchNormAct2d(\n","            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNormAct2d(\n","            2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (conv_dw): Conv2d(2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2688, bias=False)\n","          (bn2): BatchNormAct2d(\n","            2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): SiLU(inplace=True)\n","          )\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(2688, 112, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(112, 2688, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNormAct2d(\n","            448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","            (drop): Identity()\n","            (act): Identity()\n","          )\n","          (drop_path): Identity()\n","        )\n","      )\n","    )\n","    (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn2): BatchNormAct2d(\n","      1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","      (drop): Identity()\n","      (act): SiLU(inplace=True)\n","    )\n","    (global_pool): SelectAdaptivePool2d(pool_type=, flatten=Identity())\n","    (classifier): Identity()\n","  )\n","  (attention): AttentionModule(\n","    (attention): Sequential(\n","      (0): Linear(in_features=1792, out_features=1792, bias=True)\n","      (1): Sigmoid()\n","    )\n","  )\n","  (classifier): Linear(in_features=1792, out_features=17, bias=True)\n",")"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# # Access model weights\n","# model_weights = model.state_dict()\n","\n","# # Print or visualize the weights\n","# for param_tensor in model_weights:\n","#     print(param_tensor, \"\\t\", model_weights[param_tensor].size())"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8778,"status":"ok","timestamp":1700315122843,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"OvIVcSRgUPtS","outputId":"88230bf2-976f-45f6-b3b7-1a2d0ad00548"},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnewwhy2\u001b[0m (\u001b[33mnewwhy2-korea-national-open-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.17.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/data/ephemeral/home/data/newtest/wandb/run-20240810_175130-23ol8j1j</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/newwhy2-korea-national-open-university/soyoung/runs/23ol8j1j' target=\"_blank\">training</a></strong> to <a href='https://wandb.ai/newwhy2-korea-national-open-university/soyoung' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/newwhy2-korea-national-open-university/soyoung' target=\"_blank\">https://wandb.ai/newwhy2-korea-national-open-university/soyoung</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/newwhy2-korea-national-open-university/soyoung/runs/23ol8j1j' target=\"_blank\">https://wandb.ai/newwhy2-korea-national-open-university/soyoung/runs/23ol8j1j</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Epoch [1/40] - Train Loss: 0.029452431946992874: 100%|██████████| 299/299 [02:14<00:00,  2.22it/s]\n","Epoch [1/40] - Valid Loss: 0.027063028886914253: 100%|██████████| 75/75 [00:16<00:00,  4.60it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/40] Finished\n","        Train Loss: 0.43505566125505146, Train Accuracy: 0.8559322033898306, Train F1: 0.8799261397206942\n","        Valid Loss: 0.05503783078553776, Valid Accuracy: 0.9811715481171548, Valid F1: 0.9859762747167916\n","Model Saved\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [2/40] - Train Loss: 0.025415480136871338: 100%|██████████| 299/299 [02:11<00:00,  2.28it/s]  \n","Epoch [2/40] - Valid Loss: 0.000433526118285954: 100%|██████████| 75/75 [00:16<00:00,  4.64it/s]  \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/40] Finished\n","        Train Loss: 0.03882033776900307, Train Accuracy: 0.9872358233940155, Train F1: 0.9908696068390567\n","        Valid Loss: 0.061180974115850405, Valid Accuracy: 0.9815899581589959, Valid F1: 0.9837733629386617\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [3/40] - Train Loss: 0.00018701289081946015: 100%|██████████| 299/299 [02:11<00:00,  2.27it/s]\n","Epoch [3/40] - Valid Loss: 0.0006997769814915955: 100%|██████████| 75/75 [00:16<00:00,  4.62it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/40] Finished\n","        Train Loss: 0.024392559995498456, Train Accuracy: 0.9928855409081397, Train F1: 0.9943175877353861\n","        Valid Loss: 0.011324820105558804, Valid Accuracy: 0.999163179916318, Valid F1: 0.9991042966514999\n","Model Saved\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [4/40] - Train Loss: 0.008507944643497467: 100%|██████████| 299/299 [02:09<00:00,  2.31it/s]  \n","Epoch [4/40] - Valid Loss: 0.0007599102100357413: 100%|██████████| 75/75 [00:15<00:00,  4.80it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/40] Finished\n","        Train Loss: 0.011634683436179245, Train Accuracy: 0.9966520192508893, Train F1: 0.9970100131454461\n","        Valid Loss: 0.03727614790152681, Valid Accuracy: 0.9916317991631799, Valid F1: 0.9922013126246206\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [5/40] - Train Loss: 0.0015155586879700422: 100%|██████████| 299/299 [02:09<00:00,  2.32it/s] \n","Epoch [5/40] - Valid Loss: 0.00013606318680103868: 100%|██████████| 75/75 [00:15<00:00,  4.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/40] Finished\n","        Train Loss: 0.016029838498788467, Train Accuracy: 0.9953965264699728, Train F1: 0.9962490989218497\n","        Valid Loss: 0.025059503010464446, Valid Accuracy: 0.997907949790795, Valid F1: 0.9983742941755999\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [6/40] - Train Loss: 0.3602595925331116: 100%|██████████| 299/299 [02:09<00:00,  2.31it/s]    \n","Epoch [6/40] - Valid Loss: 0.0006583909853361547: 100%|██████████| 75/75 [00:15<00:00,  4.78it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [6/40] Finished\n","        Train Loss: 0.01718978109538907, Train Accuracy: 0.9945595312826951, Train F1: 0.9950610940353255\n","        Valid Loss: 0.03390380808183788, Valid Accuracy: 0.992887029288703, Valid F1: 0.9952170719194524\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [7/40] - Train Loss: 1.1351335160725284e-05: 100%|██████████| 299/299 [02:09<00:00,  2.31it/s]\n","Epoch [7/40] - Valid Loss: 8.276006701635197e-05: 100%|██████████| 75/75 [00:15<00:00,  4.80it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [7/40] Finished\n","        Train Loss: 0.01187925771046367, Train Accuracy: 0.9963381460556602, Train F1: 0.9973160522604942\n","        Valid Loss: 0.018454550314272636, Valid Accuracy: 0.99581589958159, Valid F1: 0.9970584924726782\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [8/40] - Train Loss: 1.6093177919174195e-06: 100%|██████████| 299/299 [02:09<00:00,  2.32it/s]\n","Epoch [8/40] - Valid Loss: 5.3209873840387445e-06: 100%|██████████| 75/75 [00:15<00:00,  4.80it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [8/40] Finished\n","        Train Loss: 0.006860943527633549, Train Accuracy: 0.9989537560159029, Train F1: 0.9994395058294597\n","        Valid Loss: 0.015029839516252348, Valid Accuracy: 0.9974895397489539, Valid F1: 0.9978844607493265\n","Early stopping\n","Valid Max Accuracy: 0.999163179916318\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["run = wandb.init(project = 'newwhy', name = 'training')\n","\n","# wandb에 모델의 weight & bias, graident 시각화\n","# run.watch(model, loss_fn, log = 'all', log_graph = True)\n","\n","model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, loss_fn, optimizer, device, EPOCHS, patience, model_name, run)\n","print(f'Valid Max Accuracy: {valid_max_accuracy}')"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"441a6372183d412991c827341f47ce41","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▇████████████</td></tr><tr><td>train_f1</td><td>▁▇████████████</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_accuracy</td><td>▅▅▁▆▃▇▄██▅█▇▆▇</td></tr><tr><td>valid_f1</td><td>▆▆▁▆▂▇▄▇█▆█▇▇▇</td></tr><tr><td>valid_loss</td><td>▄▄█▅▇▂▄▁▁▄▁▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.99917</td></tr><tr><td>train_f1</td><td>0.99927</td></tr><tr><td>train_loss</td><td>0.00313</td></tr><tr><td>valid_accuracy</td><td>0.99946</td></tr><tr><td>valid_f1</td><td>0.99957</td></tr><tr><td>valid_loss</td><td>0.00241</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">training</strong> at: <a href='https://wandb.ai/aistages-cv-04/soyoung/runs/rp63slnu' target=\"_blank\">https://wandb.ai/aistages-cv-04/soyoung/runs/rp63slnu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240218_213516-rp63slnu/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# run.unwatch()\n","run.finish()"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lkwxRXoBpbaX"},"source":["# 6. Inference & Save File\n","* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12776,"status":"ok","timestamp":1700315185336,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"uRYe6jlPU_Om","outputId":"2a08690c-9ffe-418d-8679-eb9280147110"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [00:23<00:00,  4.27it/s]\n"]}],"source":["model.load_state_dict(torch.load(f'./model_{model_name}.pt'))\n","model.to(device)\n","\n","preds_list = []\n","\n","model.eval()\n","for images, _ in tqdm(test_dataloader):\n","     images = images.to(device)\n","\n","     with torch.no_grad():\n","         preds = model(images)\n","     preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [08:33<00:00,  5.19s/it]"]},{"name":"stdout","output_type":"stream","text":["Ensemble Predictions: [2, 12, 5, 0, 2, 13, 0, 8, 15, 11, 5, 7, 16, 9, 15, 4, 13, 5, 13, 12, 12, 12, 1, 6, 3, 0, 7, 16, 0, 6, 7, 0, 13, 2, 13, 16, 13, 14, 4, 0, 0, 9, 1, 9, 0, 13, 13, 0, 11, 14, 13, 10, 10, 6, 7, 12, 9, 5, 13, 13, 0, 13, 5, 8, 6, 1, 5, 7, 10, 6, 13, 10, 8, 15, 13, 15, 6, 1, 12, 13, 8, 9, 9, 13, 10, 10, 5, 13, 10, 0, 3, 8, 13, 15, 7, 16, 13, 11, 14, 13, 7, 7, 13, 0, 15, 11, 2, 13, 16, 8, 6, 2, 0, 13, 12, 16, 2, 7, 11, 14, 2, 13, 5, 8, 13, 12, 4, 4, 14, 6, 5, 13, 15, 0, 16, 16, 7, 6, 6, 13, 3, 8, 0, 2, 13, 8, 3, 13, 0, 0, 6, 8, 16, 12, 11, 16, 9, 15, 6, 8, 5, 5, 10, 10, 16, 3, 9, 12, 16, 5, 2, 8, 8, 16, 9, 13, 16, 16, 3, 4, 11, 15, 9, 9, 2, 3, 13, 10, 9, 0, 4, 0, 16, 5, 14, 13, 13, 13, 0, 1, 13, 2, 6, 16, 16, 13, 8, 9, 0, 10, 5, 0, 13, 0, 11, 2, 0, 4, 0, 13, 12, 13, 16, 7, 1, 5, 7, 0, 14, 6, 0, 3, 12, 13, 9, 0, 9, 10, 9, 13, 10, 14, 9, 11, 0, 0, 1, 11, 10, 6, 3, 3, 4, 7, 14, 15, 0, 13, 12, 4, 0, 15, 13, 13, 0, 12, 13, 4, 9, 0, 8, 3, 4, 5, 0, 0, 4, 0, 9, 12, 1, 7, 7, 13, 0, 4, 15, 9, 15, 15, 9, 4, 8, 7, 15, 1, 9, 13, 8, 0, 14, 11, 6, 5, 13, 16, 13, 15, 5, 12, 4, 6, 2, 16, 7, 0, 7, 15, 8, 15, 13, 15, 11, 0, 2, 13, 16, 13, 8, 9, 16, 11, 16, 0, 16, 9, 15, 10, 6, 6, 1, 15, 0, 5, 13, 6, 7, 13, 3, 1, 16, 13, 4, 7, 13, 3, 12, 3, 3, 12, 0, 7, 13, 10, 3, 7, 12, 0, 13, 9, 15, 13, 13, 0, 9, 1, 8, 3, 4, 16, 6, 0, 0, 14, 16, 10, 13, 9, 0, 13, 9, 2, 13, 0, 8, 13, 0, 2, 4, 12, 16, 0, 7, 16, 0, 12, 11, 10, 5, 8, 16, 4, 0, 2, 13, 16, 7, 7, 11, 11, 10, 5, 13, 10, 13, 11, 5, 0, 10, 9, 4, 3, 8, 9, 7, 8, 11, 16, 0, 5, 16, 11, 3, 1, 0, 12, 0, 0, 9, 11, 13, 4, 13, 2, 11, 14, 6, 13, 7, 2, 3, 14, 6, 2, 9, 2, 9, 2, 10, 5, 0, 6, 13, 13, 8, 0, 16, 10, 9, 15, 10, 0, 0, 8, 13, 3, 15, 6, 3, 10, 0, 7, 16, 3, 7, 13, 9, 10, 0, 16, 13, 13, 0, 0, 7, 0, 13, 8, 12, 0, 13, 2, 8, 6, 15, 13, 3, 15, 10, 16, 11, 8, 0, 0, 13, 12, 0, 2, 13, 13, 0, 6, 9, 16, 0, 0, 14, 10, 3, 14, 11, 13, 2, 12, 12, 15, 11, 7, 5, 2, 13, 16, 13, 15, 5, 2, 8, 13, 2, 7, 15, 9, 14, 10, 13, 9, 13, 4, 0, 15, 0, 14, 7, 1, 13, 16, 7, 5, 6, 14, 7, 3, 2, 5, 8, 0, 3, 3, 15, 11, 14, 3, 0, 1, 3, 0, 13, 9, 2, 0, 5, 15, 7, 13, 7, 0, 2, 6, 7, 0, 6, 2, 5, 13, 0, 14, 5, 10, 16, 13, 13, 0, 2, 7, 6, 4, 13, 16, 16, 3, 3, 0, 15, 13, 12, 13, 0, 7, 13, 12, 3, 0, 11, 7, 7, 12, 2, 3, 2, 13, 14, 0, 16, 13, 16, 2, 1, 2, 9, 13, 16, 16, 15, 1, 0, 9, 4, 2, 13, 4, 13, 16, 13, 3, 9, 0, 7, 7, 13, 13, 6, 13, 0, 9, 13, 2, 1, 2, 13, 7, 12, 1, 13, 16, 5, 2, 13, 3, 2, 15, 8, 11, 6, 0, 13, 5, 0, 2, 13, 13, 0, 4, 7, 6, 9, 13, 14, 2, 9, 0, 10, 13, 16, 2, 14, 1, 5, 0, 10, 9, 0, 0, 2, 5, 13, 11, 9, 4, 9, 5, 4, 13, 0, 13, 16, 5, 11, 14, 3, 0, 0, 1, 12, 5, 6, 5, 3, 8, 0, 11, 9, 4, 7, 7, 4, 9, 0, 1, 8, 16, 4, 13, 16, 0, 13, 13, 0, 3, 10, 6, 7, 16, 8, 8, 11, 0, 8, 8, 13, 7, 0, 12, 3, 12, 7, 9, 13, 2, 2, 3, 13, 1, 12, 2, 3, 7, 9, 13, 7, 9, 0, 13, 12, 13, 4, 0, 0, 13, 4, 6, 3, 2, 3, 15, 8, 13, 4, 0, 13, 13, 5, 14, 13, 0, 10, 13, 16, 0, 10, 6, 1, 16, 8, 3, 7, 4, 15, 1, 3, 9, 11, 10, 4, 0, 3, 16, 9, 15, 15, 7, 12, 11, 0, 0, 10, 3, 2, 8, 11, 16, 16, 13, 7, 9, 7, 11, 13, 15, 2, 0, 10, 1, 15, 1, 8, 11, 16, 11, 9, 8, 4, 1, 0, 0, 9, 3, 12, 14, 2, 15, 13, 11, 0, 12, 13, 13, 16, 16, 13, 8, 1, 11, 9, 12, 6, 15, 4, 8, 9, 16, 12, 6, 14, 10, 13, 16, 0, 12, 14, 14, 11, 13, 3, 14, 9, 0, 5, 11, 3, 0, 0, 10, 0, 2, 2, 3, 7, 15, 9, 4, 4, 8, 9, 9, 15, 10, 7, 7, 2, 0, 7, 16, 11, 13, 6, 1, 2, 16, 2, 14, 0, 13, 13, 13, 0, 16, 5, 3, 0, 13, 9, 5, 15, 16, 10, 0, 16, 11, 7, 13, 0, 9, 4, 6, 14, 0, 9, 3, 13, 10, 2, 8, 1, 12, 13, 9, 15, 0, 11, 3, 2, 9, 9, 2, 7, 8, 2, 11, 7, 5, 13, 13, 14, 16, 13, 4, 6, 0, 9, 3, 6, 13, 13, 0, 13, 13, 3, 11, 9, 8, 0, 13, 5, 13, 1, 0, 1, 0, 0, 4, 2, 3, 6, 15, 0, 6, 0, 16, 16, 5, 0, 7, 1, 5, 7, 1, 3, 7, 4, 7, 6, 4, 12, 0, 0, 8, 5, 0, 9, 13, 15, 5, 12, 1, 6, 13, 6, 15, 1, 8, 0, 9, 2, 16, 4, 13, 2, 0, 13, 13, 15, 3, 12, 13, 11, 2, 10, 13, 11, 15, 2, 13, 16, 0, 0, 2, 13, 12, 5, 16, 2, 5, 3, 16, 13, 14, 3, 16, 2, 3, 11, 2, 0, 13, 2, 0, 7, 8, 0, 0, 12, 11, 12, 0, 7, 1, 11, 8, 2, 3, 13, 0, 10, 3, 9, 1, 0, 5, 9, 8, 0, 9, 4, 1, 4, 16, 10, 1, 9, 0, 9, 9, 4, 0, 9, 13, 8, 13, 11, 0, 5, 2, 13, 7, 9, 1, 8, 13, 4, 2, 9, 4, 6, 11, 12, 14, 8, 1, 10, 13, 2, 15, 2, 12, 5, 3, 2, 14, 9, 0, 13, 3, 9, 3, 13, 16, 13, 8, 13, 8, 5, 16, 7, 0, 8, 11, 8, 0, 14, 6, 11, 2, 4, 11, 11, 5, 7, 6, 7, 10, 0, 14, 0, 0, 9, 12, 6, 13, 13, 13, 13, 0, 7, 6, 2, 6, 12, 9, 3, 6, 15, 0, 7, 1, 7, 14, 14, 0, 15, 5, 7, 13, 0, 12, 0, 16, 13, 8, 12, 13, 9, 13, 13, 0, 11, 11, 15, 2, 15, 16, 7, 3, 0, 15, 16, 0, 11, 5, 14, 3, 7, 11, 5, 14, 7, 5, 16, 2, 7, 11, 4, 13, 3, 0, 9, 16, 9, 7, 5, 0, 1, 8, 14, 7, 0, 7, 0, 10, 3, 15, 12, 6, 8, 13, 8, 15, 7, 2, 4, 1, 16, 13, 10, 13, 5, 7, 9, 12, 15, 0, 0, 13, 3, 16, 13, 0, 0, 7, 15, 13, 3, 0, 8, 0, 7, 2, 13, 5, 5, 12, 2, 3, 2, 8, 8, 4, 6, 0, 13, 13, 13, 8, 7, 10, 3, 9, 3, 0, 0, 16, 0, 13, 0, 9, 6, 13, 3, 9, 5, 2, 2, 15, 13, 10, 14, 9, 2, 5, 12, 14, 11, 13, 11, 9, 8, 11, 12, 13, 1, 16, 0, 13, 2, 16, 0, 9, 7, 5, 5, 1, 9, 4, 13, 4, 2, 7, 3, 16, 7, 9, 13, 9, 16, 13, 2, 0, 11, 8, 5, 7, 5, 10, 15, 8, 9, 0, 6, 4, 0, 15, 11, 10, 0, 3, 5, 14, 13, 12, 9, 3, 7, 2, 0, 7, 9, 13, 13, 2, 0, 9, 16, 9, 1, 9, 9, 1, 15, 0, 13, 15, 6, 7, 10, 11, 16, 11, 9, 2, 4, 10, 9, 8, 9, 0, 4, 12, 13, 1, 7, 16, 0, 5, 6, 0, 3, 7, 2, 10, 4, 7, 2, 16, 9, 12, 13, 0, 0, 6, 13, 3, 1, 13, 16, 10, 12, 4, 13, 4, 8, 0, 7, 15, 15, 7, 0, 4, 8, 6, 12, 3, 11, 5, 0, 15, 1, 8, 3, 5, 8, 0, 7, 4, 0, 3, 11, 13, 13, 13, 7, 6, 0, 11, 8, 15, 7, 13, 9, 3, 13, 0, 15, 7, 8, 5, 13, 5, 0, 13, 2, 13, 8, 13, 10, 4, 13, 13, 13, 10, 3, 11, 0, 0, 1, 13, 0, 7, 3, 8, 3, 2, 13, 5, 3, 0, 12, 8, 13, 0, 12, 16, 11, 8, 7, 13, 3, 11, 13, 13, 9, 13, 16, 13, 13, 12, 13, 13, 16, 2, 13, 14, 11, 13, 12, 4, 15, 0, 6, 10, 3, 9, 16, 2, 0, 13, 9, 7, 0, 5, 0, 4, 0, 14, 12, 11, 2, 3, 14, 13, 13, 5, 13, 3, 4, 13, 9, 13, 16, 9, 13, 13, 13, 9, 0, 13, 12, 14, 15, 15, 13, 4, 8, 15, 2, 7, 2, 16, 6, 12, 9, 0, 2, 15, 5, 9, 0, 16, 3, 13, 5, 13, 5, 15, 13, 9, 3, 13, 8, 8, 10, 14, 10, 13, 1, 10, 13, 1, 4, 13, 6, 0, 2, 13, 13, 2, 10, 2, 11, 10, 0, 9, 4, 3, 10, 2, 13, 7, 16, 6, 8, 10, 1, 0, 16, 3, 4, 13, 0, 2, 0, 16, 16, 12, 2, 8, 0, 9, 16, 5, 0, 0, 3, 16, 8, 6, 1, 13, 0, 0, 14, 12, 3, 8, 3, 11, 16, 0, 10, 3, 10, 16, 2, 0, 0, 7, 0, 2, 8, 7, 2, 16, 0, 7, 13, 12, 13, 12, 11, 16, 16, 5, 10, 15, 8, 16, 13, 5, 3, 10, 7, 1, 12, 9, 7, 13, 9, 7, 0, 6, 3, 0, 16, 11, 3, 13, 1, 16, 11, 3, 9, 16, 7, 10, 6, 11, 0, 0, 9, 3, 2, 13, 12, 15, 16, 0, 0, 6, 11, 13, 0, 13, 0, 13, 8, 0, 9, 0, 5, 2, 15, 10, 2, 9, 16, 15, 9, 16, 13, 3, 9, 6, 16, 6, 7, 9, 0, 6, 15, 14, 6, 0, 16, 16, 13, 13, 2, 2, 10, 14, 7, 3, 0, 1, 10, 13, 5, 11, 1, 16, 13, 4, 12, 4, 0, 9, 14, 10, 16, 16, 16, 0, 3, 11, 9, 13, 9, 11, 0, 5, 7, 13, 16, 4, 15, 16, 14, 10, 0, 15, 4, 16, 13, 2, 13, 10, 1, 13, 0, 6, 0, 15, 12, 13, 13, 16, 2, 2, 7, 13, 13, 10, 0, 15, 11, 12, 13, 7, 0, 11, 7, 0, 11, 10, 0, 12, 15, 10, 10, 0, 3, 12, 2, 6, 7, 5, 13, 6, 13, 13, 8, 15, 16, 3, 3, 1, 3, 7, 16, 15, 5, 3, 13, 0, 14, 9, 5, 16, 2, 2, 1, 5, 16, 11, 2, 9, 10, 0, 6, 11, 2, 3, 13, 11, 16, 1, 13, 4, 2, 6, 13, 4, 13, 13, 12, 12, 13, 15, 0, 13, 13, 3, 13, 5, 8, 13, 0, 4, 10, 8, 7, 0, 11, 13, 12, 1, 11, 13, 5, 0, 0, 16, 9, 4, 10, 0, 0, 8, 0, 9, 0, 11, 13, 12, 2, 13, 15, 0, 6, 13, 16, 4, 13, 6, 13, 0, 16, 5, 13, 2, 1, 11, 15, 3, 13, 11, 0, 1, 4, 13, 13, 16, 5, 13, 0, 2, 6, 0, 13, 7, 1, 8, 9, 7, 0, 12, 13, 4, 8, 0, 8, 4, 2, 15, 14, 16, 16, 15, 13, 5, 7, 13, 10, 0, 10, 16, 9, 7, 13, 9, 7, 15, 12, 7, 0, 2, 12, 15, 1, 13, 0, 6, 2, 2, 14, 0, 6, 13, 0, 0, 0, 13, 16, 3, 4, 3, 4, 12, 10, 0, 6, 1, 0, 5, 8, 13, 13, 8, 11, 1, 13, 10, 0, 13, 4, 16, 16, 7, 7, 7, 10, 0, 4, 15, 0, 10, 10, 2, 5, 16, 5, 10, 5, 8, 12, 0, 13, 4, 12, 12, 13, 13, 13, 16, 6, 0, 10, 3, 5, 11, 14, 12, 5, 16, 4, 9, 5, 0, 6, 1, 5, 9, 0, 13, 5, 0, 4, 2, 7, 6, 10, 8, 1, 0, 0, 6, 11, 16, 10, 2, 13, 0, 6, 10, 0, 0, 9, 0, 13, 0, 11, 4, 6, 4, 0, 12, 3, 13, 15, 8, 9, 13, 3, 13, 6, 13, 0, 9, 1, 13, 13, 13, 13, 13, 16, 6, 6, 15, 0, 13, 3, 10, 0, 16, 1, 13, 2, 13, 2, 12, 2, 0, 0, 0, 4, 1, 2, 1, 0, 10, 2, 3, 7, 10, 13, 5, 7, 13, 7, 13, 1, 1, 13, 0, 13, 3, 12, 16, 13, 4, 10, 13, 0, 3, 3, 0, 4, 7, 0, 12, 12, 10, 2, 16, 8, 7, 0, 11, 11, 8, 7, 4, 0, 2, 12, 13, 11, 8, 13, 1, 4, 9, 2, 4, 11, 2, 8, 3, 11, 16, 13, 16, 3, 5, 1, 0, 13, 5, 14, 13, 3, 13, 15, 11, 12, 6, 9, 5, 13, 16, 16, 13, 11, 15, 9, 13, 0, 1, 2, 2, 11, 15, 9, 13, 2, 0, 11, 2, 1, 1, 4, 11, 2, 13, 8, 0, 2, 2, 11, 13, 14, 1, 3, 16, 4, 8, 2, 0, 16, 3, 2, 7, 11, 11, 16, 5, 15, 9, 15, 6, 16, 16, 15, 0, 7, 10, 0, 0, 0, 2, 13, 3, 2, 3, 13, 13, 8, 2, 13, 13, 1, 6, 16, 9, 13, 8, 0, 13, 0, 3, 0, 3, 9, 13, 4, 0, 16, 3, 13, 7, 5, 13, 13, 11, 13, 11, 10, 12, 4, 0, 1, 16, 5, 0, 8, 13, 7, 10, 2, 4, 7, 0, 11, 16, 0, 16, 2, 11, 1, 13, 10, 12, 0, 7, 6, 10, 10, 1, 6, 9, 13, 9, 12, 8, 7, 8, 6, 8, 16, 2, 13, 0, 5, 1, 2, 9, 13, 13, 5, 5, 7, 13, 3, 6, 0, 2, 11, 15, 14, 7, 5, 0, 5, 3, 11, 7, 2, 16, 13, 5, 16, 9, 13, 12, 16, 9, 5, 9, 0, 3, 3, 12, 13, 13, 7, 0, 16, 13, 13, 12, 2, 1, 9, 5, 7, 14, 0, 2, 10, 13, 15, 13, 15, 0, 16, 12, 3, 0, 15, 13, 0, 13, 1, 6, 0, 0, 8, 8, 10, 12, 8, 13, 4, 2, 5, 0, 5, 13, 8, 15, 8, 9, 8, 11, 13, 9, 9, 5, 10, 0, 14, 13, 0, 14, 0, 5, 11, 0, 5, 13, 14, 11, 16, 15, 13, 13, 0, 0, 5, 14, 1, 11, 11, 0, 13, 0, 5, 3, 2, 0, 4, 2, 10, 13, 7, 0, 8, 8, 15, 0, 8, 10, 0, 2, 9, 4, 13, 13, 5, 11, 0, 11, 12, 10, 13, 7, 9, 15, 4, 15, 0, 3, 0, 3, 15, 1, 12, 5, 3, 10, 8, 3, 0, 13, 0, 5, 8, 13, 10, 6, 0, 13, 0, 13, 9, 10, 11, 6, 6, 0, 0, 8, 13, 8, 10, 8, 3, 16, 7, 5, 9, 10, 2, 13, 1, 1, 15, 7, 0, 13, 6, 10, 0, 16, 12, 2, 15, 5, 8, 15, 5, 9, 0, 3, 2, 0, 0, 5, 0, 3, 3, 0, 4, 9, 13, 13, 10, 2, 10, 12, 5, 5, 13, 5, 16, 0, 3, 7, 5, 16, 5, 9, 11, 11, 13, 13, 5, 4, 9, 8, 6, 11, 14, 11, 10, 0, 11, 0, 11, 15, 10, 13, 15, 16, 13, 13, 3, 7, 12, 2, 1, 0, 0, 14, 15, 1, 15, 0, 8, 7, 13, 10, 15, 7, 13, 9, 13, 7, 3, 0, 8, 7, 16, 13, 5, 5, 15, 9, 8, 16, 9, 16, 0, 12, 6, 10, 13, 6, 9, 13, 13, 2, 0, 12, 0, 0, 11, 5, 8, 8, 16, 2, 16, 1, 0, 13, 4, 4, 9, 7, 1, 3, 14, 8, 3, 2, 5, 3, 3, 16, 0, 2, 4, 15, 13, 9, 4, 8, 12, 15, 7, 13, 13, 16, 16, 16, 15, 2, 13, 9, 10, 13, 6, 9, 7, 0, 10, 0, 16, 6, 9, 2, 14, 13, 12, 13, 7, 13, 3, 16, 12, 8, 11, 5, 15, 13, 13, 12, 0, 16, 5, 13, 5, 12, 8, 11, 4, 8, 7, 9, 13, 3, 11, 9, 0, 7, 13, 13, 0, 11, 1, 2, 13, 4, 13, 3, 0, 3, 10, 12, 7, 10, 4, 6, 0, 3, 6, 2, 8, 13, 4, 13, 7, 0, 11, 13, 3, 13, 16, 2, 3, 15, 0, 7, 1, 11, 6, 4, 4, 13, 1, 1, 3, 12, 11, 13, 0, 13, 2, 15, 13, 15, 12, 11, 6, 13, 13, 8, 15, 13, 2, 3, 8, 9, 9, 13, 3, 0, 2, 0, 2, 13, 15, 13, 15, 13, 11, 10, 13, 7, 2, 0, 4, 4, 3, 10, 11, 0, 9, 13, 3, 15, 2, 7, 2, 0, 15, 0, 2, 13, 16, 5, 2, 10, 3, 5, 13, 3, 1, 12, 11, 8, 5, 7, 2, 12, 11, 5, 11, 11, 13, 3, 13, 14, 2, 2, 0, 0, 0, 0, 4, 5, 3, 13, 10, 7, 12, 3, 10, 13, 10, 0, 7, 0, 3, 7, 13, 16, 2, 4, 15, 2, 13, 10, 5, 13, 10, 8, 16, 9, 15, 13, 15, 0, 7, 1, 16, 7, 6, 8, 12, 14, 12, 13, 9, 13, 4, 13, 13, 13, 9, 0, 12, 11, 0, 11, 2, 13, 10, 8, 0, 12]\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["model.load_state_dict(torch.load(f'./model_{model_name}.pt'))\n","model.to(device)\n","\n","N_TTA = 20\n","preds_list = []\n","with torch.no_grad():\n","    loaders = [test_dataloader] + [aug_test_dataloader] * N_TTA\n","\n","    for batches in tqdm(zip(*loaders), total=len(test_dataloader)):\n","        images, *aug_images = [images.to(device) for images, _ in batches]\n","\n","        outputs_original = model(images)\n","        outputs_augmented = [model(aug_image) for aug_image in aug_images]\n","\n","        final_outputs = (outputs_original + sum(outputs_augmented)) / N_TTA + 1\n","        preds_list.extend(final_outputs.argmax(dim=1).cpu().numpy())\n","\n","# 예측 결과 확인\n","print(\"Ensemble Predictions:\", preds_list)"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":282,"status":"ok","timestamp":1700315216829,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"aClN7Qi7VZoh"},"outputs":[],"source":["pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n","pred_df['target'] = preds_list"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1700315238836,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"VDBXQqAzVvLY"},"outputs":[],"source":["sample_submission_df = pd.read_csv(data_path + 'sample_submission.csv')\n","assert (sample_submission_df['ID'] == pred_df['ID']).all()"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":317,"status":"ok","timestamp":1700315244710,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"ePx2vCELVnuS"},"outputs":[],"source":["pred_df.to_csv(\"pred.csv\", index=False)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0008fdb22ddce0ce.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00091bffdffd83de.jpg</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00396fbc1f6cc21d.jpg</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00471f8038d9c4b6.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00901f504008d884.jpg</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     ID  target\n","0  0008fdb22ddce0ce.jpg       2\n","1  00091bffdffd83de.jpg      12\n","2  00396fbc1f6cc21d.jpg       5\n","3  00471f8038d9c4b6.jpg       0\n","4  00901f504008d884.jpg       2"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["pred_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["- 리더보드 기준 최상위 예측값 앙상블"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
